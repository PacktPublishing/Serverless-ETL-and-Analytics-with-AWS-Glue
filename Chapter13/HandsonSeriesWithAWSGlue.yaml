Description:  This template deploys various components for Data Analysis chapter of the Hands-on series with AWS Glue. 

Metadata: 
  AWS::CloudFormation::Interface: 
    ParameterGroups: 
      - 
        Label: 
          default: "Network Configuration."
        Parameters: 
          - VpcCIDR
          - PrivateSubnet1CIDR
          - PrivateSubnet2CIDR
          - PublicSubnetCIDR
          - ClientIPCIDR
      - 
        Label: 
          default: "AWS Glue Marketplace connections."
        Parameters: 
          - HudiConnectionName
          - DeltaLakeConnectionName
          - OpenSearchConnectionName
      - 
        Label: 
          default: "Amazon Redshift credentials information."
        Parameters: 
          - RedshiftMasterUserName
          - RedshiftMasterUserPassword
      - 
        Label: 
          default: "OpenSearch credentials information."
        Parameters: 
          - OpenSearchMasterUserName
          - OpenSearchMasterUserPassword

Parameters:

  VpcCIDR:
    Description: The IP range (CIDR notation) for this VPC
    Type: String
    Default: 10.0.0.0/16
    AllowedPattern: '(\d{1,3})\.(\d{1,3})\.(\d{1,3})\.(\d{1,3})/(\d{1,2})'
    ConstraintDescription: must be a valid IP CIDR range of the form x.x.x.x/x

  PrivateSubnet1CIDR:
    Description: The IP range (CIDR notation) for the private subnet in the first Availability Zone
    Type: String
    Default: 10.0.10.0/24
    AllowedPattern: '(\d{1,3})\.(\d{1,3})\.(\d{1,3})\.(\d{1,3})/(\d{1,2})'
    ConstraintDescription: must be a valid IP CIDR range of the form x.x.x.x/x
    
  PrivateSubnet2CIDR:
    Description: The IP range (CIDR notation) for the private subnet in the second Availability Zone
    Type: String
    Default: 10.0.20.0/24
    AllowedPattern: '(\d{1,3})\.(\d{1,3})\.(\d{1,3})\.(\d{1,3})/(\d{1,2})'
    ConstraintDescription: must be a valid IP CIDR range of the form x.x.x.x/x

  PublicSubnetCIDR:
    Description: The IP range (CIDR notation) for the public subnet in the first Availability Zone
    Type: String
    Default: 10.0.30.0/24
    AllowedPattern: '(\d{1,3})\.(\d{1,3})\.(\d{1,3})\.(\d{1,3})/(\d{1,2})'
    ConstraintDescription: must be a valid IP CIDR range of the form x.x.x.x/x

  KeyName:
    Type: AWS::EC2::KeyPair::KeyName
    Description: The KeyPair to be used in your EC2 instance. This EC2 instance will be used as a proxy to connect from your SQL client to Aurora postgres source database.
    ConstraintDescription: Please select a key to be used to login to the EC2 instance
    
  EC2ImageId:
    Type: AWS::SSM::Parameter::Value<AWS::EC2::Image::Id>
    Description: Latest AMI ID of windows. You can keep the default value for this.
    Default: /aws/service/ami-windows-latest/Windows_Server-2016-English-Full-Base

  HudiConnectionName:
    Description: The name of the AWS Glue Hudi Connection created in Glue Studio.
    Type: String

  DeltaLakeConnectionName:
    Description: The name of the AWS Glue Delta Lake Connection created in Glue Studio.
    Type: String    

  OpenSearchConnectionName:
    Description: The name of the AWS Glue OpenSearch Connection created in Glue Studio.
    Type: String  

  RedshiftMasterUserName:
    Description: The master user name for the Redshift cluster.
    Type: String 

  RedshiftMasterUserPassword:
    Description: The master user password for the Redshift cluster. Must have atleast 8 characters, one upper case, one lower case and one number. Special characters are not allowed.
    Type: String
    AllowedPattern: '^(?=.*[A-Za-z])(?=.*[0-9])[A-Za-z0-9]{8,}$'
    ConstraintDescription: Must have atleast 8 characters, one upper case, one lower case and one number. Special characters are not allowed.    
    NoEcho: true
    MinLength: 8
    MaxLength: 64

  OpenSearchMasterUserName:
    Description: The master user name for the OpenSearch cluster.
    Type: String 

  OpenSearchMasterUserPassword:
    Description: "The master user password for the OpenSearch cluster. Must have atleast 8 characters, one upper case, one lower case and one number and one of #$! special characters."
    Type: String
    NoEcho: true
    AllowedPattern: '^(?=.*[A-Za-z])(?=.*[0-9])(?=.*[#$!])[A-Za-z0-9#$!]{8,}$'
    ConstraintDescription: "Must have atleast 8 characters, one upper case, one lower case and one number and one of #$! special characters."
    MinLength: 8
    MaxLength: 64

  ClientIPCIDR:
    Type: String
    Description: The IP Address of your Client that will be used to connect to the Kafka cluster. On Mac, you can run the following command to get your IP in CIDR notation using - curl ipecho.net/plain ; echo /32
    AllowedPattern: '(\d{1,3})\.(\d{1,3})\.(\d{1,3})\.(\d{1,3})/(\d{1,2})'
    ConstraintDescription: must be a valid IP CIDR range of the form x.x.x.x/x   

Resources:

  VPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: !Ref VpcCIDR
      EnableDnsSupport: true
      EnableDnsHostnames: true
      Tags:
        -
          Key: Project
          Value: HandsonSeriesWithAWSGlue

  InternetGateway:
    Type: AWS::EC2::InternetGateway
    Properties:
      Tags:
        -
          Key: Project
          Value: HandsonSeriesWithAWSGlue  
      
  VPCInternetGatewayAttachment:
    Type: AWS::EC2::VPCGatewayAttachment
    DependsOn:
      - InternetGateway
      - VPC      
    Properties:
      VpcId: !Ref VPC
      InternetGatewayId: !Ref InternetGateway
      
  PublicSubnet:
    Type: AWS::EC2::Subnet
    DependsOn:
      - VPC    
    Properties:
      AvailabilityZone: !Select [0, !GetAZs '']
      CidrBlock: !Ref PublicSubnetCIDR
      MapPublicIpOnLaunch: true
      VpcId: !Ref VPC
      Tags:
        -
          Key: Project
          Value: HandsonSeriesWithAWSGlue
        
  PrivateSubnet1:
    Type: AWS::EC2::Subnet
    DependsOn:
      - VPC
      - PrivateRouteTable
    Properties:
      AvailabilityZone: !Select [ 0, !GetAZs  '' ]
      CidrBlock: !Ref PrivateSubnet1CIDR
      MapPublicIpOnLaunch: false
      VpcId: !Ref VPC      
      Tags:
        -
          Key: Project
          Value: HandsonSeriesWithAWSGlue
        
  PrivateSubnet2:
    Type: AWS::EC2::Subnet
    DependsOn:
      - VPC     
    Properties:
      AvailabilityZone: !Select [ 1, !GetAZs  '' ]
      CidrBlock: !Ref PrivateSubnet2CIDR
      MapPublicIpOnLaunch: false
      VpcId: !Ref VPC      
      Tags:
        -
          Key: Project
          Value: HandsonSeriesWithAWSGlue

  PrivateRouteTable:
    Type: AWS::EC2::RouteTable
    DependsOn:
      - VPC    
    Properties:
      VpcId: !Ref VPC
      Tags:
        -
          Key: Project
          Value: HandsonSeriesWithAWSGlue
        
  PublicRouteTable:
    Type: AWS::EC2::RouteTable
    DependsOn:
      - VPC    
    Properties:
      VpcId: !Ref VPC
      Tags:
        -
          Key: Project
          Value: HandsonSeriesWithAWSGlue

  NatGatewayEIP:
    Type: AWS::EC2::EIP
    DependsOn: VPCInternetGatewayAttachment
    Properties:
      Domain: vpc

  NatGateway:
    Type: AWS::EC2::NatGateway
    DependsOn:
      - NatGatewayEIP
      - PublicSubnet    
    Properties:
      AllocationId: !GetAtt NatGatewayEIP.AllocationId
      SubnetId: !Ref PublicSubnet
      
  PrivateSubnetRouteTableAssociation1:
    Type: AWS::EC2::SubnetRouteTableAssociation
    DependsOn:
      - PrivateRouteTable
      - PrivateSubnet1
    Properties:
      RouteTableId: !Ref PrivateRouteTable
      SubnetId: !Ref PrivateSubnet1

  PrivateSubnetRouteTableAssociation2:
    Type: AWS::EC2::SubnetRouteTableAssociation
    DependsOn:
      - PrivateRouteTable
      - PrivateSubnet2
    Properties:
      RouteTableId: !Ref PrivateRouteTable
      SubnetId: !Ref PrivateSubnet2

  PublicSubnetRouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    DependsOn:
      - PublicRouteTable
      - PublicSubnet    
    Properties:
      RouteTableId: !Ref PublicRouteTable    
      SubnetId: !Ref PublicSubnet
        
  PublicInternetRoute:
    Type: AWS::EC2::Route
    DependsOn:
      - PublicRouteTable
      - InternetGateway 
    Properties:
      RouteTableId: !Ref PublicRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId: !Ref InternetGateway

  DefaultPrivateRoute:
    Type: AWS::EC2::Route
    DependsOn:
      - PrivateRouteTable
      - NatGateway     
    Properties:
      RouteTableId: !Ref PrivateRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      NatGatewayId: !Ref NatGateway
      
  ChapterDataAnalysisSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    DependsOn:
      - VPC    
    Properties:
      GroupName: chapter-data-analysis-sg
      GroupDescription: Security group to protect Data Analysis Chapter resources.
      VpcId: !Ref VPC
      Tags:
        -
          Key: Project
          Value: HandsonSeriesWithAWSGlue
        
  SelfRefSecurityGroupIngress:
    Type: AWS::EC2::SecurityGroupIngress
    DependsOn: ChapterDataAnalysisSecurityGroup
    Properties:
      GroupId: !Ref ChapterDataAnalysisSecurityGroup
      IpProtocol: tcp
      FromPort: 0
      ToPort: 65535
      Description: Self-referencing rule
      SourceSecurityGroupId: !GetAtt ChapterDataAnalysisSecurityGroup.GroupId

  SecurityGroupIngressForEC2RDPConnection:
    Type: AWS::EC2::SecurityGroupIngress
    DependsOn:
      - ChapterDataAnalysisSecurityGroup
    Properties:
      GroupId: !Ref ChapterDataAnalysisSecurityGroup
      IpProtocol: tcp
      FromPort: 3389
      ToPort: 3389
      Description: Rule to allow Remote desktop connection from your laptop. This will help us view the OpenSearch Dashboards hosted in a private subnet.
      CidrIp: !Ref ClientIPCIDR

  SelfRefSecurityGroupEgress:
    Type: AWS::EC2::SecurityGroupEgress
    DependsOn: ChapterDataAnalysisSecurityGroup
    Properties:
      GroupId: !Ref ChapterDataAnalysisSecurityGroup
      IpProtocol: tcp
      FromPort: 0
      ToPort: 65535
      Description: Self-referencing rule required by Glue
      SourceSecurityGroupId: !GetAtt ChapterDataAnalysisSecurityGroup.GroupId

  SecurityGroupEgress443:
    Type: AWS::EC2::SecurityGroupEgress
    DependsOn: ChapterDataAnalysisSecurityGroup
    Properties: 
      Description: Egress to install yum packages
      CidrIp: "0.0.0.0/0"
      FromPort: 443
      GroupId: !Ref ChapterDataAnalysisSecurityGroup
      IpProtocol: tcp
      ToPort: 443
  
  SecurityGroupEgress80:
    Type: AWS::EC2::SecurityGroupEgress
    DependsOn: ChapterDataAnalysisSecurityGroup
    Properties: 
      Description: Egress to install yum packages
      CidrIp: "0.0.0.0/0"
      FromPort: 80
      GroupId: !Ref ChapterDataAnalysisSecurityGroup
      IpProtocol: tcp
      ToPort: 80

  SecurityGroupEgress5432:
    Type: AWS::EC2::SecurityGroupEgress
    DependsOn: ChapterDataAnalysisSecurityGroup
    Properties: 
      Description: Kafka Connectivity
      CidrIp: !Ref VpcCIDR
      FromPort: 9094
      GroupId: !Ref ChapterDataAnalysisSecurityGroup
      IpProtocol: tcp
      ToPort: 9094

  TargetS3Bucket:
    Type: AWS::S3::Bucket
    DependsOn: KMSEncryptionKey    
    DeletionPolicy: Delete
    Properties:
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: aws:kms
              KMSMasterKeyID: !GetAtt KMSEncryptionKey.Arn      
      Tags:
        -
          Key: Project
          Value: HandsonSeriesWithAWSGlue

  ScriptAndTempS3Bucket:
    Type: AWS::S3::Bucket
    DependsOn: KMSEncryptionKey    
    DeletionPolicy: Delete
    Properties:
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: aws:kms
              KMSMasterKeyID: !GetAtt KMSEncryptionKey.Arn  
      Tags:
        -
          Key: Project
          Value: HandsonSeriesWithAWSGlue

  S3VPCEndpoint:
    Type: AWS::EC2::VPCEndpoint
    DependsOn:
      - PrivateRouteTable
      - VPC
      - TargetS3Bucket
      - ScriptAndTempS3Bucket
    Properties:
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - 
            Principal: "*"
            Effect: Allow
            Action:
              - s3:PutObject
              - s3:GetObject
              - s3:ListBucket
              - s3:DeleteObject
            Resource:
              - !Join ['', ["arn:aws:s3:::", !Ref TargetS3Bucket]]
              - !Join ['', ["arn:aws:s3:::", !Ref TargetS3Bucket, "/*"]]
              - !Join ['', ["arn:aws:s3:::", !Ref ScriptAndTempS3Bucket]]
              - !Join ['', ["arn:aws:s3:::", !Ref ScriptAndTempS3Bucket, "/*"]]
          - 
            Principal: "*"
            Effect: Allow
            Action:
              - s3:Get*
            Resource:
              - !Join ['', ["arn:aws:s3:::prod-", !Ref AWS::Region, "-starport-layer-bucket/*"]]              
      RouteTableIds:
        - !Ref PrivateRouteTable
      ServiceName: !Sub com.amazonaws.${AWS::Region}.s3
      VpcId: !Ref VPC      

  RSAccessRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: HandsonSeriesWithAWSGlueRSRole
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - redshift.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: /
      Tags:
        -
          Key: Project
          Value: HandsonSeriesWithAWSGlue

  ReqdForRSToAccessGlueCatalog:
    Type: AWS::IAM::ManagedPolicy
    DependsOn:
      - RSAccessRole
    Properties:
      ManagedPolicyName: ReqdForRSToAccessGlueCatalog
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - 
            Effect: Allow
            Action:
              - glue:GetDatabase
              - glue:GetPartition
              - glue:GetPartitions
              - glue:BatchGetPartition
              - glue:GetDatabases
              - glue:GetTables
              - glue:GetTable
            Resource: '*'
          - 
            Effect: Allow
            Action:
              - s3:GetObject
              - s3:ListBucket
            Resource:
              - !Join ['', ["arn:aws:s3:::", !Ref TargetS3Bucket]]
              - !Join ['', ["arn:aws:s3:::", !Ref TargetS3Bucket, "/*"]]              
      Roles:
        - HandsonSeriesWithAWSGlueRSRole

  ExecuteGlueJobRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: HandsonSeriesWithAWSGlueJobRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - glue.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: /
      Tags:
        -
          Key: Project
          Value: HandsonSeriesWithAWSGlue

  ReqdForGlueJobsToExecute:
    Type: AWS::IAM::ManagedPolicy
    DependsOn:
      - ExecuteGlueJobRole
      - TargetS3Bucket
      - ScriptAndTempS3Bucket
    Properties:
      ManagedPolicyName: ReqdForGlueJobsToExecute
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - 
            Effect: Allow
            Action:
              - glue:Batch*
              - glue:Update*
              - glue:Create*
              - glue:Delete*
              - glue:Get*
              - glue:Reset*
              - glue:Untag*
              - glue:Tag*
            Resource: '*'
          - 
            Effect: Allow
            Action:
              - logs:CreateLogGroup
              - logs:CreateLogStream
              - logs:PutLogEvents
              - logs:AssociateKmsKey
            Resource: arn:aws:logs:*:*:/aws-glue/*         
          - 
            Effect: Allow
            Action:
              - ec2:DescribeVpcEndpoints
              - ec2:DescribeRouteTables
              - ec2:DescribeNetworkInterfaces
              - ec2:DescribeSecurityGroups
              - ec2:DescribeSubnets
              - ec2:DescribeVpcAttribute
              - ec2:CreateTags
              - ec2:DeleteTags
              - ec2:CreateNetworkInterface
              - ec2:DeleteNetworkInterface
            Resource: '*'
          - 
            Effect: Allow
            Action:
              - cloudwatch:PutMetricData
            Resource: '*'
          - 
            Effect: Allow
            Action:
              - iam:GetRole
            Resource: '*'
          - 
            Effect: Allow
            Action:
              - s3:GetBucketLocation
              - s3:ListBucket
              - s3:GetBucketAcl
              - s3:GetObject
              - s3:PutObject
              - s3:DeleteObject
            Resource:
              - !Join ['', ["arn:aws:s3:::", !Ref ScriptAndTempS3Bucket]]
              - !Join ['', ["arn:aws:s3:::", !Ref ScriptAndTempS3Bucket, "/*"]]  
              - !Join ['', ["arn:aws:s3:::", !Ref TargetS3Bucket]]
              - !Join ['', ["arn:aws:s3:::", !Ref TargetS3Bucket, "/*"]]                           
          - 
            Effect: Allow
            Action:
              - lakeformation:UpdateTableStorageOptimizer
              - lakeformation:StartQueryPlanning
              - lakeformation:GetDataAccess
              - lakeformation:DeleteObjectsOnCancel
              - lakeformation:CommitTransaction
              - lakeformation:CancelTransaction
              - lakeformation:ExtendTransaction
              - lakeformation:StartTransaction
              - lakeformation:UpdateTableObjects
            Resource: '*'     
          - 
            Effect: Allow
            Action:
              - secretsmanager:GetSecretValue
              - secretsmanager:DescribeSecret
              - secretsmanager:ListSecrets
            Resource: !Sub arn:aws:secretsmanager:${AWS::Region}:${AWS::AccountId}:secret:ChapterDataAnalysisOSSecret*          
          - 
            Effect: Allow
            Action:
              - secretsmanager:GetSecretValue
              - secretsmanager:DescribeSecret
              - secretsmanager:ListSecrets
            Resource: !Sub arn:aws:secretsmanager:${AWS::Region}:${AWS::AccountId}:secret:ChapterDataAnalysisOSSecret*
          -
            Effect: Allow
            Action:
              - kms:Encrypt
              - kms:Decrypt
              - kms:ReEncrypt*
              - kms:GenerateDataKey
              - kms:GenerateDataKeyWithoutPlaintext
              - kms:GenerateDataKeyPairWithoutPlaintext
              - kms:GenerateDataKeyPair
              - kms:DescribeKey
            Resource: !Sub arn:aws:kms:${AWS::Region}:${AWS::AccountId}:key/*
      Roles:
        - HandsonSeriesWithAWSGlueJobRole

  ExecuteLambdaFnsRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: HandsonSeriesWithAWSGlueExecuteLambdaFnsRole
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: /
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/CloudWatchLogsFullAccess
      Tags:
        -
          Key: Project
          Value: HandsonSeriesWithAWSGlue

  ReqdToTriggerLambdaFns:
    Type: AWS::IAM::ManagedPolicy
    DependsOn:
      - ExecuteLambdaFnsRole
      - TargetS3Bucket
      - ScriptAndTempS3Bucket
    Properties:
      ManagedPolicyName: ReqdToTriggerLambdaFns
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - 
            Effect: Allow
            Action:
              - glue:DeleteTable
              - glue:Get*
              - glue:BatchStopJobRun
            Resource: '*'
          - 
            Effect: Allow
            Action:
              - ec2:DetachNetworkInterface
              - ec2:DescribeNetworkInterfaces
              - ec2:DeleteNetworkInterface
            Resource: '*'
          -
            Effect: Allow
            Action: 
              - logs:*
            Resource:
              - !Sub arn:aws:logs:*:${AWS::AccountId}:log-group:/aws/lambda/InvokeHandsonSeriesWithAWSGlueStarterTasks
              - !Sub arn:aws:logs:*:${AWS::AccountId}:log-group:/aws/lambda/InvokeHandsonSeriesWithAWSGlueStarterTasks:log-stream:*
          -
            Effect: Allow
            Action:
              - s3:*
            Resource:
              - !Join ['', ["arn:aws:s3:::", !Ref ScriptAndTempS3Bucket]]
              - !Join ['', ["arn:aws:s3:::", !Ref ScriptAndTempS3Bucket, "/*"]]  
              - !Join ['', ["arn:aws:s3:::", !Ref TargetS3Bucket]]
              - !Join ['', ["arn:aws:s3:::", !Ref TargetS3Bucket, "/*"]]         
          -
            Effect: Allow
            Action:
                - s3:GetObject
                - s3:ListObjects
                - s3:ListBucket
            Resource:
                - arn:aws:s3:::packt-serverless-etl-glue
                - arn:aws:s3:::packt-serverless-etl-glue/HandsonSeriesWithAWSGlue/*
          - 
            Effect: Allow
            Action:
              - kms:Encrypt
              - kms:Decrypt
              - kms:ReEncrypt*
              - kms:GenerateDataKey
              - kms:GenerateDataKeyWithoutPlaintext
              - kms:GenerateDataKeyPairWithoutPlaintext
              - kms:GenerateDataKeyPair
              - kms:DescribeKey
            Resource: '*'                 
      Roles:
        - HandsonSeriesWithAWSGlueExecuteLambdaFnsRole

  ExecuteStarterTasksLambdaFn:
    Type: AWS::Lambda::Function
    DependsOn:
      - ReqdToTriggerLambdaFns
      - ExecuteLambdaFnsRole
      - ScriptAndTempS3Bucket
      - TargetS3Bucket
    Properties:
      Code:
        ZipFile: |
          from time import sleep
          import boto3
          import json
          import urllib3
          
          glue = boto3.client('glue')
          s3 = boto3.resource('s3')
          ec2 = boto3.client('ec2')
          s3_client = boto3.client('s3')
          http = urllib3.PoolManager()

          def lambda_handler(event, context):
            print('Event: %s' % json.dumps(event))
            response = { 'StackId': event['StackId'], 'RequestId': event['RequestId'], 'LogicalResourceId': event['LogicalResourceId'] }
            resProps = event['ResourceProperties']
            if event['RequestType'] == 'Create':
              try:
                for i in s3_client.list_objects_v2(Bucket='packt-serverless-etl-glue',Prefix='HandsonSeriesWithAWSGlue/')['Contents']:
                  src = {'Bucket': 'packt-serverless-etl-glue','Key': i['Key']}
                  s3.meta.client.copy(src, resProps['S3Dep'], i['Key'])
                response.update({ 'Status': 'SUCCESS', 'PhysicalResourceId': 'InitSetupDone' })
              except Exception as e:
                response.update({ 'Status': 'FAILED', 'Reason': str(e), 'PhysicalResourceId': 'InitSetupFailed' })
            if event['RequestType'] == 'Delete':
              try:
                s3.Bucket(resProps['S3Dep']).objects.delete()
                s3.Bucket(resProps['S3Target']).objects.delete()
                try:
                  try:
                    streaming_job_run = glue.get_job_runs(JobName='09 - Kafka Consumer for Data Analysis Chapter',MaxResults=1)['JobRuns'][0]
                    if streaming_job_run['JobRunState'] == 'RUNNING':
                      glue.batch_stop_job_run(JobName='09 - Kafka Consumer for Data Analysis Chapter',JobRunIds=[streaming_job_run['Id']])
                  except Exception as e:
                    if e.response['Error']['Code'] == 'EntityNotFoundException':
                      pass                      
                  try:
                    streaming_job_run = glue.get_job_runs(JobName='10 - DeltaStreamer Kafka Consumer for Data Analysis Chapter',MaxResults=1)['JobRuns'][0]
                    if streaming_job_run['JobRunState'] == 'RUNNING':
                      glue.batch_stop_job_run(JobName='10 - DeltaStreamer Kafka Consumer for Data Analysis Chapter',JobRunIds=[streaming_job_run['Id']])
                  except Exception as e:
                    if e.response['Error']['Code'] == 'EntityNotFoundException':
                      pass 
                  enis = ec2.describe_network_interfaces(Filters=[{'Name':'description','Values':['Attached to Glue using role: arn:aws:iam::'+resProps['Account']+':role/HandsonSeriesWithAWSGlueJobRole']}])['NetworkInterfaces']
                  eni_ids = [i['NetworkInterfaceId'] for i in enis]
                  attachment_ids = [i['Attachment']['AttachmentId'] for i in enis if 'Attachment' in i] 
                  print('Detaching ENIs section started.')
                  for i in attachment_ids:
                    try:
                      ec2.detach_network_interface(AttachmentId=i,DryRun=False,Force=True)
                    except Exception as e:
                      if e.response['Error']['Code'] == 'InvalidAttachmentID.NotFound':
                        pass
                      else:
                        response.update({ 'Status': 'FAILED', 'Reason': str(e), 'PhysicalResourceId': 'InitSetupDeleteFailed' })
                  print('Detaching ENIs section completed.')
                  sleep(30)
                  print('Deleting ENIs section started.')
                  for i in eni_ids:
                    try:
                      ec2.delete_network_interface(DryRun=False,NetworkInterfaceId=i)
                    except Exception as e:
                      if e.response['Error']['Code'] == 'InvalidNetworkInterfaceID.NotFound':
                        pass
                      else:
                        response.update({ 'Status': 'FAILED', 'Reason': str(e), 'PhysicalResourceId': 'InitSetupDeleteFailed' })
                  print('Deleting ENIs section completed.')                        
                except Exception as e:
                  response.update({ 'Status': 'FAILED', 'Reason': str(e), 'PhysicalResourceId': 'InitSetupDeleteFailed' })
                response.update({ 'Status': 'SUCCESS', 'PhysicalResourceId': 'InitSetupDelete' })
              except Exception as e:
                response.update({ 'Status': 'FAILED', 'Reason': str(e), 'PhysicalResourceId': 'InitSetupDeleteFailed' })
            if event['RequestType'] == 'Update':
              response.update({ 'Status': 'SUCCESS', 'PhysicalResourceId': 'InitSetupNothingChanged' })
            resp = http.request('PUT', event['ResponseURL'], body = json.dumps(response), headers = {'Content-Type': 'application/json'}, retries = False)
            print('http resp:' + resp.data.decode('utf-8'))
            print(response)
            return(response)
      FunctionName: InvokeHandsonSeriesWithAWSGlueStarterTasks
      MemorySize: 128
      Runtime: python3.9
      Description: Lambda function for starter tasks.
      Handler: index.lambda_handler
      Role: !GetAtt ExecuteLambdaFnsRole.Arn
      Timeout: 900      
      Tags:
        -
          Key: Project
          Value: HandsonSeriesWithAWSGlue

  ExecuteStarterTasks:
    Type: Custom::ExecuteStarterTasks
    DependsOn:
      - ExecuteStarterTasksLambdaFn
      - ScriptAndTempS3Bucket
      - TargetS3Bucket
    Properties:
      ServiceToken: !GetAtt ExecuteStarterTasksLambdaFn.Arn
      S3Dep: !Ref ScriptAndTempS3Bucket
      S3Target: !Ref TargetS3Bucket
      Account: !Ref AWS::AccountId

  EC2InstanceForRDP:
    Type: AWS::EC2::Instance
    DependsOn:
      - ChapterDataAnalysisSecurityGroup
      - PublicSubnet
    Properties:
      InstanceType: t3.small
      KeyName: !Ref KeyName
      ImageId: !Ref EC2ImageId
      SecurityGroupIds:
        - !GetAtt ChapterDataAnalysisSecurityGroup.GroupId
      SubnetId: !Ref PublicSubnet
      BlockDeviceMappings: 
      - DeviceName: /dev/sda1
        Ebs:
          Encrypted: false
          VolumeType: gp2
          DeleteOnTermination: true
          VolumeSize: 30
      Tags:
        -
          Key: Project
          Value: HandsonSeriesWithAWSGlue

  GluePrivateResourcesConnection:
    Type: AWS::Glue::Connection
    DependsOn:
      - ChapterDataAnalysisSecurityGroup
      - PrivateSubnet1
    Properties: 
      CatalogId: !Ref AWS::AccountId
      ConnectionInput: 
        ConnectionType: NETWORK
        Description: Connection to access the kafka topic and Opensearch from Glue job.
        Name: private_resources_network_connection
        PhysicalConnectionRequirements:
          SecurityGroupIdList:
            - !GetAtt ChapterDataAnalysisSecurityGroup.GroupId
          SubnetId: !Ref PrivateSubnet1
          AvailabilityZone: !GetAtt PrivateSubnet1.AvailabilityZone

  ChapterDataAnalysisGlueDatabase:
    Type: AWS::Glue::Database
    Properties: 
      CatalogId: !Ref AWS::AccountId
      DatabaseInput: 
        Description: All tables in this chapter will be created within this database.
        Name: chapter-data-analysis-glue-database
        LocationUri: !Join ['', ["s3://", !Ref TargetS3Bucket, "/"]]

  DeltaStreamerStreamingJob:
    Type: AWS::Glue::Job
    DependsOn:
      - ScriptAndTempS3Bucket
      - TargetS3Bucket
      - ExecuteGlueJobRole
      - ReqdForGlueJobsToExecute
      - GluePrivateResourcesConnection
      - ExecuteStarterTasks
    Properties:
      Description: This job acts as a deltastreamer consumer of the kafka topic.
      Command:
        Name: gluestreaming
        ScriptLocation: !Join ['', ["s3://", !Ref ScriptAndTempS3Bucket, "/HandsonSeriesWithAWSGlue/scripts/DeltaStreamer Kafka Consumer for Data Analysis Chapter.scala"]]
        PythonVersion: 3
      DefaultArguments:
        '--enable-glue-datacatalog': ''
        '--enable-continuous-cloudwatch-log': 'true'
        '--enable-metrics': ''
        '--TempDir': !Join ['', ["s3://", !Ref ScriptAndTempS3Bucket, "/temp/DeltaStreamerKafkaConsumerForDataAnalysisChapter"]]
        '--job-language': 'scala'
        '--TARGET_BUCKET': !Ref TargetS3Bucket
        '--CONFIG_BUCKET': !Ref ScriptAndTempS3Bucket
        '--job-bookmark-option': job-bookmark-disable
        '--class': 'GlueApp'
        '--extra-jars': '/tmp/*'
      MaxRetries: 0
      Name: 10 - DeltaStreamer Kafka Consumer for Data Analysis Chapter
      GlueVersion: 3.0
      Role: !GetAtt ExecuteGlueJobRole.Arn
      WorkerType: Standard
      NumberOfWorkers: 2
      Timeout: 2880
      ExecutionProperty:
        MaxConcurrentRuns: 1
      Connections:
        Connections:
          - !Ref HudiConnectionName
          - !Ref GluePrivateResourcesConnection
      Tags:
        Project: HandsonSeriesWithAWSGlue

  KafkaConsumerForDataAnalysisChapterJob:
    Type: AWS::Glue::Job
    DependsOn:
      - ScriptAndTempS3Bucket
      - TargetS3Bucket
      - ExecuteGlueJobRole
      - ReqdForGlueJobsToExecute
      - GluePrivateResourcesConnection
      - ExecuteStarterTasks
    Properties:
      Description: This job acts as a consumer of the kafka topic.
      Command:
        Name: gluestreaming
        ScriptLocation: !Join ['', ["s3://", !Ref ScriptAndTempS3Bucket, "/HandsonSeriesWithAWSGlue/scripts/Kafka Consumer for Data Analysis Chapter.py"]]
        PythonVersion: 3
      DefaultArguments:
        '--enable-glue-datacatalog': ''
        '--enable-continuous-cloudwatch-log': 'true'
        '--enable-metrics': ''
        '--TempDir': !Join ['', ["s3://", !Ref ScriptAndTempS3Bucket, "/temp/KafkaConsumerForDataAnalysisChapter"]]
        '--job-language': 'python'
        '--TARGET_BUCKET': !Ref TargetS3Bucket
        '--job-bookmark-option': job-bookmark-disable
      MaxRetries: 0
      Name: 09 - Kafka Consumer for Data Analysis Chapter
      GlueVersion: 3.0
      Role: !GetAtt ExecuteGlueJobRole.Arn
      WorkerType: Standard
      NumberOfWorkers: 2
      Timeout: 2880
      ExecutionProperty:
        MaxConcurrentRuns: 1
      Connections:
        Connections:
          - !Ref HudiConnectionName
          - !Ref GluePrivateResourcesConnection
      Tags:
        Project: HandsonSeriesWithAWSGlue

  SeedDataJobForDataAnalysisChapterJob:
    Type: AWS::Glue::Job
    DependsOn:
      - ScriptAndTempS3Bucket
      - ExecuteGlueJobRole
      - ReqdForGlueJobsToExecute
    Properties:
      Description: This job creates seed data that will be used in the rest of the chapter.
      Command:
        Name: glueetl
        ScriptLocation: !Join ['', ["s3://", !Ref ScriptAndTempS3Bucket, "/HandsonSeriesWithAWSGlue/scripts/Seed data job for Data Analysis Chapter.py"]]
        PythonVersion: 3
      DefaultArguments:
        '--enable-glue-datacatalog': ''
        '--enable-continuous-cloudwatch-log': 'true'
        '--enable-metrics': ''
        '--TempDir': !Join ['', ["s3://", !Ref ScriptAndTempS3Bucket, "/temp/SeedDataJobForDataAnalysisChapter"]]
        '--job-language': 'python'
        '--job-bookmark-option': job-bookmark-disable
        '--TARGET_BUCKET': !Ref TargetS3Bucket
      MaxRetries: 0
      Name: 01 - Seed data job for Data Analysis Chapter
      GlueVersion: 3.0
      Role: !GetAtt ExecuteGlueJobRole.Arn
      WorkerType: Standard
      NumberOfWorkers: 2
      Timeout: 2880
      ExecutionProperty:
        MaxConcurrentRuns: 1
      Tags:
        Project: HandsonSeriesWithAWSGlue

  DeltaLakeIncrementalLoadForDataAnalysisChapterJob:
    Type: AWS::Glue::Job
    DependsOn:
      - ScriptAndTempS3Bucket
      - ExecuteGlueJobRole
      - ReqdForGlueJobsToExecute
    Properties:
      Description: This job processes incremental data for DeltaLake table.
      Command:
        Name: glueetl
        ScriptLocation: !Join ['', ["s3://", !Ref ScriptAndTempS3Bucket, "/HandsonSeriesWithAWSGlue/scripts/DeltaLake Incremental load for Data Analysis Chapter.py"]]
        PythonVersion: 3
      DefaultArguments:
        '--enable-glue-datacatalog': ''
        '--enable-continuous-cloudwatch-log': 'true'
        '--enable-metrics': ''
        '--TempDir': !Join ['', ["s3://", !Ref ScriptAndTempS3Bucket, "/temp/DeltaLakeIncrementalLoadForDataAnalysisChapter"]]
        '--extra-py-files': /tmp/delta-core_2.12-1.0.0.jar
        '--job-language': 'python'
        '--job-bookmark-option': job-bookmark-disable
        '--TARGET_BUCKET': !Ref TargetS3Bucket
      MaxRetries: 0
      Name: 05 - DeltaLake Incremental load for Data Analysis Chapter
      GlueVersion: 3.0
      Role: !GetAtt ExecuteGlueJobRole.Arn
      WorkerType: Standard
      NumberOfWorkers: 2
      Timeout: 2880
      ExecutionProperty:
        MaxConcurrentRuns: 1
      Connections:
        Connections:
          - !Ref DeltaLakeConnectionName
      Tags:
        Project: HandsonSeriesWithAWSGlue

  DeltaLakeInitLoadForDataAnalysisChapterJob:
    Type: AWS::Glue::Job
    DependsOn:
      - ScriptAndTempS3Bucket
      - ExecuteGlueJobRole
      - ReqdForGlueJobsToExecute
    Properties:
      Description: This job processes initial load data for DeltaLake table.
      Command:
        Name: glueetl
        ScriptLocation: !Join ['', ["s3://", !Ref ScriptAndTempS3Bucket, "/HandsonSeriesWithAWSGlue/scripts/DeltaLake Init load for Data Analysis Chapter.py"]]
        PythonVersion: 3
      DefaultArguments:
        '--enable-glue-datacatalog': ''
        '--enable-continuous-cloudwatch-log': 'true'
        '--enable-metrics': ''
        '--TempDir': !Join ['', ["s3://", !Ref ScriptAndTempS3Bucket, "/temp/DeltaLakeInitLoadForDataAnalysisChapter"]]
        '--extra-py-files': /tmp/delta-core_2.12-1.0.0.jar
        '--job-language': 'python'
        '--job-bookmark-option': job-bookmark-disable
        '--TARGET_BUCKET': !Ref TargetS3Bucket
        '--DELTALAKE_CONNECTION_NAME': !Ref DeltaLakeConnectionName
      MaxRetries: 0
      Name: 04 - DeltaLake Init load for Data Analysis Chapter
      GlueVersion: 3.0
      Role: !GetAtt ExecuteGlueJobRole.Arn
      WorkerType: Standard
      NumberOfWorkers: 2
      Timeout: 2880
      ExecutionProperty:
        MaxConcurrentRuns: 1
      Connections:
        Connections:
          - !Ref DeltaLakeConnectionName
      Tags:
        Project: HandsonSeriesWithAWSGlue

  GovernedTableCreateTableForDataAnalysisChapterJob:
    Type: AWS::Glue::Job
    DependsOn:
      - ScriptAndTempS3Bucket
      - ExecuteGlueJobRole
      - ReqdForGlueJobsToExecute
    Properties:
      Description: This job creates the Goverened table.
      Command:
        Name: pythonshell
        ScriptLocation: !Join ['', ["s3://", !Ref ScriptAndTempS3Bucket, "/HandsonSeriesWithAWSGlue/scripts/Governed Table Create Table for Data Analysis Chapter.py"]]
        PythonVersion: 3
      DefaultArguments:
        '--job-bookmark-option': job-bookmark-disable
        '--job-language': 'python'
        '--TARGET_BUCKET': !Ref TargetS3Bucket
      MaxRetries: 0
      Name: 06 - Governed Table Create Table for Data Analysis Chapter
      GlueVersion: 1.0
      Role: !GetAtt ExecuteGlueJobRole.Arn
      MaxCapacity: 0.0625
      Timeout: 2880
      ExecutionProperty:
        MaxConcurrentRuns: 1
      Tags:
        Project: HandsonSeriesWithAWSGlue

  GovernedTableInitLoadForDataAnalysisChapterJob:
    Type: AWS::Glue::Job
    DependsOn:
      - ScriptAndTempS3Bucket
      - ExecuteGlueJobRole
      - ReqdForGlueJobsToExecute
    Properties:
      Description: This job processes initial load data for Governed table.
      Command:
        Name: glueetl
        ScriptLocation: !Join ['', ["s3://", !Ref ScriptAndTempS3Bucket, "/HandsonSeriesWithAWSGlue/scripts/Governed Table Init Load for Data Analysis Chapter.py"]]
        PythonVersion: 3
      DefaultArguments:
        '--enable-glue-datacatalog': ''
        '--enable-continuous-cloudwatch-log': 'true'
        '--enable-metrics': ''
        '--TempDir': !Join ['', ["s3://", !Ref ScriptAndTempS3Bucket, "/temp/GovernedTableInitLoadForDataAnalysisChapter"]]
        '--job-language': 'python'
        '--job-bookmark-option': job-bookmark-disable
        '--TARGET_BUCKET': !Ref TargetS3Bucket
      MaxRetries: 0
      Name: 07 - Governed Table Init Load for Data Analysis Chapter
      GlueVersion: 3.0
      Role: !GetAtt ExecuteGlueJobRole.Arn
      WorkerType: Standard
      NumberOfWorkers: 2
      Timeout: 2880
      ExecutionProperty:
        MaxConcurrentRuns: 1
      Tags:
        Project: HandsonSeriesWithAWSGlue

  HudiIncrementalLoadForDataAnalysisChapterJob:
    Type: AWS::Glue::Job
    DependsOn:
      - ScriptAndTempS3Bucket
      - ExecuteGlueJobRole
      - ReqdForGlueJobsToExecute
    Properties:
      Description: This job processes incremental load data for Hudi table.
      Command:
        Name: glueetl
        ScriptLocation: !Join ['', ["s3://", !Ref ScriptAndTempS3Bucket, "/HandsonSeriesWithAWSGlue/scripts/Hudi Incremental load for Data Analysis Chapter.py"]]
        PythonVersion: 3
      DefaultArguments:
        '--enable-glue-datacatalog': ''
        '--enable-continuous-cloudwatch-log': 'true'
        '--enable-metrics': ''
        '--TempDir': !Join ['', ["s3://", !Ref ScriptAndTempS3Bucket, "/temp/HudiIncrementalLoadForDataAnalysisChapter"]]
        '--job-language': 'python'
        '--job-bookmark-option': job-bookmark-disable
        '--TARGET_BUCKET': !Ref TargetS3Bucket
      MaxRetries: 0
      Name: 03 - Hudi Incremental load for Data Analysis Chapter
      GlueVersion: 3.0
      Role: !GetAtt ExecuteGlueJobRole.Arn
      WorkerType: Standard
      NumberOfWorkers: 2
      Timeout: 2880
      ExecutionProperty:
        MaxConcurrentRuns: 1
      Connections:
        Connections:
          - !Ref HudiConnectionName
      Tags:
        Project: HandsonSeriesWithAWSGlue

  HudiInitLoadForDataAnalysisChapterJob:
    Type: AWS::Glue::Job
    DependsOn:
      - ScriptAndTempS3Bucket
      - ExecuteGlueJobRole
      - ReqdForGlueJobsToExecute
    Properties:
      Description: This job processes initial load data for Hudi table.
      Command:
        Name: glueetl
        ScriptLocation: !Join ['', ["s3://", !Ref ScriptAndTempS3Bucket, "/HandsonSeriesWithAWSGlue/scripts/Hudi Init load for Data Analysis Chapter.py"]]
        PythonVersion: 3
      DefaultArguments:
        '--enable-glue-datacatalog': ''
        '--enable-continuous-cloudwatch-log': 'true'
        '--enable-metrics': ''
        '--TempDir': !Join ['', ["s3://", !Ref ScriptAndTempS3Bucket, "/temp/HudiInitLoadForDataAnalysisChapter"]]
        '--job-language': 'python'
        '--job-bookmark-option': job-bookmark-disable
        '--TARGET_BUCKET': !Ref TargetS3Bucket
      MaxRetries: 0
      Name: 02 - Hudi Init load for Data Analysis Chapter
      GlueVersion: 3.0
      Role: !GetAtt ExecuteGlueJobRole.Arn
      WorkerType: Standard
      NumberOfWorkers: 2
      Timeout: 2880
      ExecutionProperty:
        MaxConcurrentRuns: 1
      Connections:
        Connections:
          - !Ref HudiConnectionName
      Tags:
        Project: HandsonSeriesWithAWSGlue

  KafkaProducerForDataAnalysisChapterJob:
    Type: AWS::Glue::Job
    DependsOn:
      - ScriptAndTempS3Bucket
      - ExecuteGlueJobRole
      - ReqdForGlueJobsToExecute
      - GluePrivateResourcesConnection
    Properties:
      Description: This job will load the initial data in a Kafka topic.
      Command:
        Name: pythonshell
        ScriptLocation: !Join ['', ["s3://", !Ref ScriptAndTempS3Bucket, "/HandsonSeriesWithAWSGlue/scripts/Kafka Producer for Data Analysis Chapter.py"]]
        PythonVersion: 3
      DefaultArguments:
        '--extra-py-files': !Join ['', ["s3://", !Ref ScriptAndTempS3Bucket, "/HandsonSeriesWithAWSGlue/dependencies/kafka_python-2.0.2-py2.py3-none-any.whl,s3://", !Ref ScriptAndTempS3Bucket, "/HandsonSeriesWithAWSGlue/dependencies/awswrangler-2.14.0-py3-none-any.whl"]]
        '--job-bookmark-option': job-bookmark-disable
        '--job-language': 'python'
        '--TARGET_BUCKET': !Ref TargetS3Bucket
      MaxRetries: 0
      Name: 08 - Kafka Producer for Data Analysis Chapter
      GlueVersion: 1.0
      Role: !GetAtt ExecuteGlueJobRole.Arn
      MaxCapacity: 0.0625
      Timeout: 2880
      ExecutionProperty:
        MaxConcurrentRuns: 1
      Connections:
        Connections:
          - !Ref GluePrivateResourcesConnection
      Tags:
        Project: HandsonSeriesWithAWSGlue

  IncrementalDataKafkaProducerForDataAnalysisChapterJob:
    Type: AWS::Glue::Job
    DependsOn:
      - ScriptAndTempS3Bucket
      - ExecuteGlueJobRole
      - ReqdForGlueJobsToExecute
      - GluePrivateResourcesConnection
    Properties:
      Description: This job will load the incremental data in a Kafka topic.
      Command:
        Name: pythonshell
        ScriptLocation: !Join ['', ["s3://", !Ref ScriptAndTempS3Bucket, "/HandsonSeriesWithAWSGlue/scripts/Incremental Data Kafka Producer for Data Analysis Chapter.py"]]
        PythonVersion: 3
      DefaultArguments:
        '--extra-py-files': !Join ['', ["s3://", !Ref ScriptAndTempS3Bucket, "/HandsonSeriesWithAWSGlue/dependencies/kafka_python-2.0.2-py2.py3-none-any.whl,s3://", !Ref ScriptAndTempS3Bucket, "/HandsonSeriesWithAWSGlue/dependencies/awswrangler-2.14.0-py3-none-any.whl"]]
        '--job-bookmark-option': job-bookmark-disable
        '--job-language': 'python'
      MaxRetries: 0
      Name: 11 - Incremental Data Kafka Producer for Data Analysis Chapter
      GlueVersion: 1.0
      Role: !GetAtt ExecuteGlueJobRole.Arn
      MaxCapacity: 0.0625
      Timeout: 2880
      ExecutionProperty:
        MaxConcurrentRuns: 1
      Connections:
        Connections:
          - !Ref GluePrivateResourcesConnection
      Tags:
        Project: HandsonSeriesWithAWSGlue

  OpenSearchLoadForDataAnalysisChapterJob:
    Type: AWS::Glue::Job
    DependsOn:
      - ScriptAndTempS3Bucket
      - ExecuteGlueJobRole
      - ReqdForGlueJobsToExecute
      - OpensearchDomain
    Properties:
      Description: This job loads the data into Opensearch domain.
      Command:
        Name: glueetl
        ScriptLocation: !Join ['', ["s3://", !Ref ScriptAndTempS3Bucket, "/HandsonSeriesWithAWSGlue/scripts/OpenSearch Load for Data Analysis Chapter.py"]]
        PythonVersion: 3
      DefaultArguments:
        '--enable-glue-datacatalog': ''
        '--enable-continuous-cloudwatch-log': 'true'
        '--enable-metrics': ''
        '--TempDir': !Join ['', ["s3://", !Ref ScriptAndTempS3Bucket, "/temp/OpenSearchLoadForDataAnalysisChapter"]]
        '--job-language': 'python'
        '--job-bookmark-option': job-bookmark-disable
        '--DOMAIN_ENDPOINT': !GetAtt OpensearchDomain.DomainEndpoint
      MaxRetries: 0
      Name: 12 - OpenSearch Load for Data Analysis Chapter
      GlueVersion: 3.0
      Role: !GetAtt ExecuteGlueJobRole.Arn
      WorkerType: Standard
      NumberOfWorkers: 2
      Timeout: 2880
      ExecutionProperty:
        MaxConcurrentRuns: 1
      Connections:
        Connections:
          - !Ref OpenSearchConnectionName
          - !Ref GluePrivateResourcesConnection
      Tags:
        Project: HandsonSeriesWithAWSGlue

  MSKSourceCluster:
    Type: AWS::MSK::Cluster
    DependsOn:
      - PrivateSubnet1
      - PrivateSubnet2
      - ChapterDataAnalysisSecurityGroup
      - ExecuteStarterTasks
    Properties:
      ClusterName: !Sub msk-source-cluster-${AWS::StackName}
      KafkaVersion: 2.6.2
      NumberOfBrokerNodes: 2
      EncryptionInfo:
        EncryptionAtRest:
          DataVolumeKMSKeyId: !GetAtt KMSEncryptionKey.Arn
        EncryptionInTransit:
          ClientBroker: TLS
          InCluster: true
      BrokerNodeGroupInfo:
        BrokerAZDistribution: DEFAULT
        SecurityGroups:
          - !GetAtt ChapterDataAnalysisSecurityGroup.GroupId
        InstanceType: kafka.m5.large
        StorageInfo:
          EBSStorageInfo:
            VolumeSize: 100
        ClientSubnets:
          - !Ref PrivateSubnet1
          - !Ref PrivateSubnet2

  LFServiceLinkedRole:
    Type: AWS::IAM::ServiceLinkedRole
    Properties:
      AWSServiceName: lakeformation.amazonaws.com
      Description: Service linked role for AWS Lake Formation

  KMSEncryptionKey:
    Type: AWS::KMS::Key
    DependsOn: LFServiceLinkedRole
    Properties: 
      Description: Key to encrypt resources.
      Enabled: true
      KeyPolicy: 
        Version: 2012-10-17
        Statement:
          - 
            Sid: Enable IAM User Permissions
            Effect: Allow
            Principal:
              AWS: !Sub arn:aws:iam::${AWS::AccountId}:root
              Service:
                - !Sub logs.${AWS::Region}.amazonaws.com
                - es.amazonaws.com
                - glue.amazonaws.com
                - redshift.amazonaws.com
                - secretsmanager.amazonaws.com
                - lambda.amazonaws.com
            Action: 
              - kms:*
            Resource: '*'
          - 
            Sid: Allow use of the key
            Effect: Allow
            Principal: 
              AWS:
                - !Sub arn:aws:iam::${AWS::AccountId}:role/aws-service-role/lakeformation.amazonaws.com/AWSServiceRoleForLakeFormationDataAccess
                - !GetAtt RSAccessRole.Arn
            Action:
              - kms:Encrypt
              - kms:Decrypt
              - kms:ReEncrypt*
              - kms:GenerateDataKey
              - kms:GenerateDataKeyWithoutPlaintext
              - kms:GenerateDataKeyPairWithoutPlaintext
              - kms:GenerateDataKeyPair
              - kms:DescribeKey
            Resource: '*'            
      Tags:
        -
          Key: Project
          Value: HandsonSeriesWithAWSGlue

  KMSEncryptionKeyAlias:
    Type: AWS::KMS::Alias
    DependsOn: KMSEncryptionKey
    Properties:
      AliasName: alias/resource-encryption-key
      TargetKeyId: !Ref KMSEncryptionKey

  OSApplicationLogs: 
    Type: AWS::Logs::LogGroup
    DependsOn: KMSEncryptionKey
    Properties: 
      RetentionInDays: 7
      LogGroupName: !Sub /aws/opensearch/domains/data-analysis-os-domain/application-logs
      KmsKeyId: !GetAtt KMSEncryptionKey.Arn
      Tags:
        -
          Key: Project
          Value: HandsonSeriesWithAWSGlue

  OSIndexLogs: 
    Type: AWS::Logs::LogGroup
    DependsOn: KMSEncryptionKey
    Properties: 
      RetentionInDays: 7
      LogGroupName: !Sub /aws/opensearch/domains/data-analysis-os-domain/index-logs
      KmsKeyId: !GetAtt KMSEncryptionKey.Arn
      Tags:
        -
          Key: Project
          Value: HandsonSeriesWithAWSGlue

  OSSearchLogs: 
    Type: AWS::Logs::LogGroup
    DependsOn: KMSEncryptionKey
    Properties: 
      RetentionInDays: 7
      LogGroupName: !Sub /aws/opensearch/domains/data-analysis-os-domain/search-logs
      KmsKeyId: !GetAtt KMSEncryptionKey.Arn
      Tags:
        -
          Key: Project
          Value: HandsonSeriesWithAWSGlue

  OSAuditLogs: 
    Type: AWS::Logs::LogGroup
    DependsOn: KMSEncryptionKey
    Properties: 
      RetentionInDays: 7
      LogGroupName: !Sub /aws/opensearch/domains/data-analysis-os-domain/audit-logs
      KmsKeyId: !GetAtt KMSEncryptionKey.Arn
      Tags:
        -
          Key: Project
          Value: HandsonSeriesWithAWSGlue

  OpensearchServiceLinkedRole:
    Type: AWS::IAM::ServiceLinkedRole
    Properties: 
      AWSServiceName: opensearchservice.amazonaws.com
      Description: This service linked role is required to successfully create the opensearch domain. Read here for more - https://docs.aws.amazon.com/opensearch-service/latest/developerguide/slr.html

  OpensearchLogsResourcePolicy:
    Type: AWS::Logs::ResourcePolicy
    Properties:
      PolicyName: "OpenSearchServiceLogsResourcePolicy"
      PolicyDocument: '{"Version": "2012-10-17","Statement":[{"Effect":"Allow","Principal": {"Service": ["es.amazonaws.com"]},"Action":["logs:PutLogEvents","logs:CreateLogStream"],"Resource":"*"}]}'


  OpensearchDomain:
    Type: AWS::OpenSearchService::Domain
    DependsOn: 
      - KMSEncryptionKey
      - OSApplicationLogs
      - OSIndexLogs
      - OSSearchLogs
      - OSAuditLogs
      - PrivateSubnet1
      - PrivateSubnet2
      - ChapterDataAnalysisSecurityGroup
      - OpensearchServiceLinkedRole
      - OpensearchLogsResourcePolicy
      - ExecuteStarterTasks
    Properties:
      DomainName: !Sub data-analysis-os-domain
      EngineVersion: OpenSearch_1.2
      DomainEndpointOptions:
        EnforceHTTPS: true
        TLSSecurityPolicy: Policy-Min-TLS-1-2-2019-07
      ClusterConfig:
        DedicatedMasterEnabled: true
        InstanceCount: 2
        ZoneAwarenessEnabled: true
        InstanceType: m5.large.search
        DedicatedMasterType: m5.large.search
        DedicatedMasterCount: 3
      AdvancedSecurityOptions:
        Enabled: true
        InternalUserDatabaseEnabled: true
        MasterUserOptions:
          MasterUserName: !Ref OpenSearchMasterUserName
          MasterUserPassword: !Ref OpenSearchMasterUserPassword
      EncryptionAtRestOptions:
        Enabled: true
        KmsKeyId: !GetAtt KMSEncryptionKey.Arn
      LogPublishingOptions:
        ES_APPLICATION_LOGS:
          CloudWatchLogsLogGroupArn: !GetAtt OSApplicationLogs.Arn
          Enabled: true
        INDEX_SLOW_LOGS:
          CloudWatchLogsLogGroupArn: !GetAtt OSIndexLogs.Arn
          Enabled: true
        SEARCH_SLOW_LOGS:
          CloudWatchLogsLogGroupArn: !GetAtt OSSearchLogs.Arn
          Enabled: true
        AUDIT_LOGS:
          CloudWatchLogsLogGroupArn: !GetAtt OSAuditLogs.Arn
          Enabled: true
      NodeToNodeEncryptionOptions:
        Enabled: true
      EBSOptions:
        EBSEnabled: true
        Iops: 0
        VolumeSize: 100
        VolumeType: gp2
      SnapshotOptions: {}
      Tags:
       -
        Key: Project
        Value: HandsonSeriesWithAWSGlue      
      VPCOptions:
        SecurityGroupIds:
          - Ref: ChapterDataAnalysisSecurityGroup
        SubnetIds:
          - Ref: PrivateSubnet1
          - Ref: PrivateSubnet2
      AccessPolicies:
        Version: 2012-10-17
        Statement:
          -
            Effect: "Allow"
            Principal:
              AWS: '*'
            Action:
              - es:*
            Resource: !Sub arn:aws:es:${AWS::Region}:${AWS::AccountId}:domain/data-analysis-os-domain/*
          -
            Effect: "Allow"
            Principal:
              AWS: '*'
            Action:
              - logs:PutLogEvents
              - logs:CreateLogStream
            Resource: !Sub arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/opensearch/domains/data-analysis-os-domain/*
            Resource: '*'
      AdvancedOptions:
        rest.action.multi.allow_explicit_index: true

  ChapterDataAnalysisRedshiftClusterSubnetGroup:
    Type: AWS::Redshift::ClusterSubnetGroup
    DependsOn: 
      - PrivateSubnet1
      - PrivateSubnet2
    Properties: 
      Description: The subnet group to be associated with the Redshift cluster for the Data Analysis chapter.
      SubnetIds: 
        - !Ref PrivateSubnet1
        - !Ref PrivateSubnet2
      Tags:
        -
          Key: Project
          Value: HandsonSeriesWithAWSGlue

  ChapterDataAnalysisRedshiftCluster:
    Type: AWS::Redshift::Cluster
    DependsOn: 
      - KMSEncryptionKey
      - ChapterDataAnalysisSecurityGroup
      - ChapterDataAnalysisRedshiftClusterSubnetGroup
      - RSAccessRole
      - ExecuteStarterTasks
    Properties: 
      AllowVersionUpgrade: false
      AquaConfigurationStatus: auto
      VpcSecurityGroupIds: 
        - !GetAtt ChapterDataAnalysisSecurityGroup.GroupId
      ClusterSubnetGroupName: !Ref ChapterDataAnalysisRedshiftClusterSubnetGroup
      ClusterType: single-node
      ClusterVersion: 1.0
      DBName: dev
      Encrypted: true
      EnhancedVpcRouting: true
      IamRoles: 
        - !GetAtt RSAccessRole.Arn
      KmsKeyId: !GetAtt KMSEncryptionKey.Arn
      MasterUsername: !Ref RedshiftMasterUserName
      MasterUserPassword: !Ref RedshiftMasterUserPassword
      NodeType: ds2.xlarge
      PubliclyAccessible: false
      Tags:
        -
          Key: Project
          Value: HandsonSeriesWithAWSGlue

  ChapterDataAnalysisOpenSearchDomainSecret:
    Type: AWS::SecretsManager::Secret
    Properties:
      Name: ChapterDataAnalysisOSSecret
      Description: This is the username and password of the master user of OpenSearch domain created for Data Analysis chapter.
      KmsKeyId: !GetAtt KMSEncryptionKey.Arn
      SecretString: !Sub '{"es.net.http.auth.user": "${OpenSearchMasterUserName}", "es.net.http.auth.pass": "${OpenSearchMasterUserPassword}"}'
      Tags:
        -
          Key: Project
          Value: HandsonSeriesWithAWSGlue

Outputs:
  PublicIPOfEC2InstanceForRDP:
    Description: Public IP of the EC2 instance.
    Value: !GetAtt EC2InstanceForRDP.PublicIp

  InstanceIDOfEC2InstanceForRDP:
    Description: Instance ID of the EC2 instance that will be used for OpenSearch dashboards.
    Value: !Ref EC2InstanceForRDP

  TargetS3Bucket:
    Description: S3 bucket that will store the output from the Glue job.
    Value: !Ref TargetS3Bucket

  OpensearchDomainARN:
    Description: The ARN of the Opensearch Domain
    Value: !GetAtt OpensearchDomain.Arn

  VPCId:
    Description: The VPCId to be used while creating the Glue MSK Connection.
    Value: !Ref VPC

  PrivateSubnet1Id:
    Description: The PrivateSubnet1 to be used while creating the Glue MSK Connection and Serverless Redshift.
    Value: !Ref PrivateSubnet1

  PrivateSubnet2Id:
    Description: The PrivateSubnet2 to be used while creating the Glue MSK Connection and Serverless Redshift.
    Value: !Ref PrivateSubnet2

  ChapterDataAnalysisSecurityGroup:
    Description: The Security Group Id to be used while creating the Glue MSK Connection and Serverless Redshift.
    Value: !Ref ChapterDataAnalysisSecurityGroup

  LakeFormationLocationForRegistry:
    Description: The location to be registered in LakeFormation for LakeFormation Governed Tables.
    Value: !Join ['', ["s3://", !Ref TargetS3Bucket, "/employees_governed_table/"]]    

  RedshiftClusterId:
    Description: The id of the Redshift cluster. This will be required to select the correct cluster to connect.
    Value: !Ref ChapterDataAnalysisRedshiftCluster

  OpenSearchDashboardsURL:
    Description: The URL to be used in your EC2 instance to open the OpenSearch Dashboards.
    Value: !Join ['', ["https://", !GetAtt OpensearchDomain.DomainEndpoint, "/_dashboards"]]
